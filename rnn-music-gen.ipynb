{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyqBKJMi6f7S"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9MpKWmX6h-u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8gVqtUw6loL"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('dpcq.txt', 'https://www.txt990.org/api/txt_down.php?articleid=297&articlename=%E6%96%97%E7%A0%B4%E8%8B%8D%E7%A9%B9')\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGeDLjM6kF1M"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -y fluidsynth\n",
        "\n",
        "!pip install --upgrade pyfluidsynth\n",
        "\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7R3xAHK6pLr"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import datetime\n",
        "import fluidsynth\n",
        "import glob\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict, List, Optional, Sequence, Tuple\n",
        "\n",
        "_SAMPLING_RATE = 16000\n",
        "\n",
        "sample_file = tf.keras.utils.get_file('chpn_op23.mid','http://www.piano-midi.de/midis/chopin/chpn_op23.mid')\n",
        "sample_file1 = tf.keras.utils.get_file('chp_op31_format0.mid','http://www.piano-midi.de/midis/chopin/chp_op31_format0.mid')\n",
        "sample_file2 = tf.keras.utils.get_file('chpn_op53_format0.mid','http://www.piano-midi.de/midis/chopin/chpn_op53_format0.mid')\n",
        "\n",
        "bach = tf.keras.utils.get_file('bwv988.mid','http://www.jsbach.net/midi/bwv988/bwv988.mid')\n",
        "\n",
        "pm = pretty_midi.PrettyMIDI(sample_file)\n",
        "pm1 = pretty_midi.PrettyMIDI(sample_file1)\n",
        "pm2 = pretty_midi.PrettyMIDI(sample_file2)\n",
        "pmbach = pretty_midi.PrettyMIDI(bach)\n",
        "\n",
        "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
        "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
        "  instrument = pm.instruments[0]\n",
        "  notes = collections.defaultdict(list)\n",
        "\n",
        "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "  prev_start = sorted_notes[0].start\n",
        "\n",
        "  for note in sorted_notes:\n",
        "    start = note.start\n",
        "    end = note.end\n",
        "    notes['pitch'].append(note.pitch)\n",
        "    notes['start'].append(start)\n",
        "    notes['end'].append(end)\n",
        "    notes['step'].append(start - prev_start)\n",
        "    notes['duration'].append(end - start)\n",
        "    prev_start = start\n",
        "\n",
        "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IrpaD67tm4T"
      },
      "outputs": [],
      "source": [
        "#raw_notes = [midi_to_notes(sample_file),midi_to_notes(sample_file1),midi_to_notes(sample_file2),]\n",
        "raw_notes = [midi_to_notes(bach),midi_to_notes(sample_file),midi_to_notes(sample_file1),midi_to_notes(sample_file2)]\n",
        "print('Number of instruments:', len(pm.instruments))\n",
        "instrument = pm.instruments[0]\n",
        "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
        "print('Instrument name:', instrument_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrV1k0J98mOH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijidAHgm9JxF"
      },
      "outputs": [],
      "source": [
        "text = ''\n",
        "for rawn in raw_notes:\n",
        "  for i, note in rawn.iterrows():\n",
        "    for times in range(round(note['duration']/0.07)):\n",
        "      text += chr(int(note['pitch']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rk13G3i0iXB"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))\n",
        "\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "sequences = ids_dataset.batch(151, drop_remainder=True)\n",
        "\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 1024\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 2048\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tqNvtFM3MjC"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Py3zLK1fJT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss, run_eagerly=True)\n",
        "checkpoint_dir = './music'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrhyaqfxQdjn"
      },
      "outputs": [],
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model.load_weights(latest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq1ZaXiR1Los"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "  model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB6X_Eoo1UKM"
      },
      "outputs": [],
      "source": [
        " class OneStep(tf.keras.Model):\n",
        "     def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "         super().__init__()\n",
        "             self.temperature = temperature\n",
        "                 self.model = model\n",
        "                     self.chars_from_ids = chars_from_id. class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    \n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TvCRYqc2ie7"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
        "states = None\n",
        "next_char = tf.constant(['0'])\n",
        "#result = [next_char]\n",
        "\n",
        "raw = []\n",
        "for n in range(2000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  #result.append(next_char)\n",
        "  raw.append(ord(tf.strings.join(next_char).numpy().decode('utf-8')))\n",
        "#result = tf.strings.join(result)\n",
        "#print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS2wU_Lfp4t5"
      },
      "outputs": [],
      "source": [
        "def notes_to_midi(\n",
        "  raw,\n",
        "  out_file: str, \n",
        "  instrument_name: str,\n",
        "  velocity: int = 100,  # note loudness\n",
        ") -> pretty_midi.PrettyMIDI:\n",
        "\n",
        "  pm = pretty_midi.PrettyMIDI()\n",
        "  instrument = pretty_midi.Instrument(\n",
        "      program=pretty_midi.instrument_name_to_program(\n",
        "          instrument_name))\n",
        "\n",
        "  start,end = 0,0\n",
        "  for i in range(len(raw)-1):\n",
        "    if raw[i]==raw[i+1]:\n",
        "      end += 0.2\n",
        "    else:\n",
        "      note = pretty_midi.Note(\n",
        "          velocity=velocity,\n",
        "          pitch=int(raw[i]),\n",
        "          start=start,\n",
        "          end = end,\n",
        "      )\n",
        "      instrument.notes.append(note)\n",
        "      start = end\n",
        "  pm.instruments.append(instrument)\n",
        "  pm.write(out_file)\n",
        "  return pm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8w9NTMWs4QP"
      },
      "outputs": [],
      "source": [
        "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=60):\n",
        "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
        "  # Take a sample of the generated waveform to mitigate kernel resets\n",
        "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
        "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "glxZNjvVtx15"
      },
      "outputs": [],
      "source": [
        "example_file = 'example.midi'\n",
        "example_pm = notes_to_midi(\n",
        "    raw, out_file=example_file, instrument_name=instrument_name)\n",
        "display_audio(example_pm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qjmmcAvOeUUq"
      },
      "outputs": [],
      "source": [
        "ori = []\n",
        "for chr in text:\n",
        "  ori.append(ord(chr))\n",
        "example_pm = notes_to_midi(\n",
        "    ori, out_file=example_file, instrument_name=instrument_name)\n",
        "display_audio(example_pm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}